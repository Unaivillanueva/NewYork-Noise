{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: 'style-table.css'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6422040972ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'style-table.css'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'style-notebook.css'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<style>{}</style>'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: 'style-table.css'"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    data = pd.read_csv(filename)\n",
    "    return data\n",
    "\n",
    "# change this to your local file\n",
    "filename = 'NYNoise.csv'\n",
    "# read file\n",
    "data = readfile(filename)\n",
    "# crimes match row count\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data doesn't contain the full data for 2015 and 2017 we will just use the year 2016; otherwise we wuold have double data for some months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#add a column with the year from the Date\n",
    "data['year'] = pd.DatetimeIndex(data['Created Date']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the dataset. Just keep the rows that belong to year 2016.\n",
    "data2016 = data[data['year'] == 2016]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#check that we successfully removed the other cases\n",
    "data2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print number of cases in 2016\n",
    "print \"Total number of cases in 2016:\", len(data2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the cases are more common in certian areas of the city. We will take a llok at the most prominent ones: Construction Before/After Hours (NM1), Barking Dog (NR5), Alarms (NR3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#start by creating a dataset for each type of case\n",
    "#Construction\n",
    "construction_data = data2016[data2016['Descriptor'] == 'Noise: Construction Before/After Hours (NM1)']\n",
    "#Barking Dog\n",
    "barkingDog_data = data2016[data2016['Descriptor'] == 'Noise, Barking Dog (NR5)']\n",
    "#Alarms\n",
    "alarms_data =  data2016[data2016['Descriptor'] == 'Noise: Alarms (NR3)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to obtain the latitudes and longitudes for the plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "#define function\n",
    "def obtain_lat_long(data):\n",
    "    latitude = [float(item) for item in data['Latitude'] if not math.isnan(item)] #we need to remove some 'NaN' values\n",
    "    longitude = [float(item) for item in data['Longitude'] if not math.isnan(item)]\n",
    "    geodata = {\"lat\": latitude,\n",
    "                \"lon\": longitude}\n",
    "    return geodata\n",
    "\n",
    "#create dicts for each type\n",
    "lat_lon_construction = obtain_lat_long(construction_data)\n",
    "lat_lon_barkingdog = obtain_lat_long(barkingDog_data)\n",
    "lat_lon_alarms = obtain_lat_long(alarms_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import geoplotlib \n",
    "import numpy as np\n",
    "from geoplotlib.utils import BoundingBox\n",
    "\n",
    "def plot_geodata(geodata, cmap_color):\n",
    "\n",
    "    # plot kernel density map\n",
    "    geoplotlib.kde(geodata, bw=5, cut_below=1e-4, cmap=cmap_color)\n",
    "    #we define limits for the bounding box\n",
    "    n = max(geodata['lat']) \n",
    "    s = min(geodata['lat'])\n",
    "    e = max(geodata['lon'])\n",
    "    w = min(geodata['lon']) \n",
    "    # create bounding box\n",
    "    bbox = BoundingBox(north=n, south=s, west=w, east=e)\n",
    "    # set bouding box\n",
    "    geoplotlib.set_bbox(bbox)\n",
    "    geoplotlib.inline()\n",
    "    \n",
    "print \"Construction:\"\n",
    "plot_geodata(lat_lon_construction, 'hot')\n",
    "print \"Barking Dogs\"\n",
    "plot_geodata(lat_lon_barkingdog, 'hot')\n",
    "print \"Alarms\"\n",
    "plot_geodata(lat_lon_alarms, 'hot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate rows for of each type\n",
    "construction = construction_data.shape[0]\n",
    "dogbarking = barkingDog_data.shape[0]\n",
    "alarms = alarms_data.shape[0]\n",
    "total = (construction + dogbarking + alarms)\n",
    "print \"Number of noise cases: %d \" % construction\n",
    "print \"Amount of barking dog cases: %d\" % dogbarking\n",
    "print \"Number of alarm: %d\" % alarms\n",
    "print 'Total: {}'.format(total)\n",
    "print \"Percentage of noise cases:\", construction/(total/100)\n",
    "print \"Percentage of barking dog cases:\", dogbarking/(total/100)\n",
    "print \"Percentage of alarm:\", alarms/(total/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#we will work with the unbalanced data\n",
    "def get_types(dataset, case_type):\n",
    "    df = dataset[dataset['Descriptor'].isin(case_type)]\n",
    "    # filter the dataset. Just keep the rows that don't have NaN lat/lon\n",
    "    df = df[np.isfinite(df['Latitude'])]\n",
    "    return df\n",
    "\n",
    "case_types = ['Noise: Construction Before/After Hours (NM1)', 'Noise, Barking Dog (NR5)', 'Noise: Alarms (NR3)']\n",
    "plotting_data = get_types(data2016, case_types)\n",
    "print len(plotting_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a grid of SF with N*N points\n",
    "N = 100\n",
    "geo_data = obtain_lat_long(data2016)\n",
    "\n",
    "#we define the size of the grid to fit the map\n",
    "n = max(geo_data['lat']) \n",
    "s = min(geo_data['lat'])\n",
    "e = max(geo_data['lon']) \n",
    "w = min(geo_data['lon']) \n",
    "    \n",
    "#we obtain the partitions for lat and lon.\n",
    "latitude_partition = np.arange(s, n, float(n-s)/N)\n",
    "longitude_partition = np.arange(w, e, float(e-w)/N)\n",
    "    \n",
    "# reset north, south, west and east in order to set the boundingbox\n",
    "n = np.mean(geo_data[\"lat\"]) + 0.135\n",
    "s = np.mean(geo_data[\"lat\"]) - 0.15\n",
    "e = np.mean(geo_data[\"lon\"]) + 0.135\n",
    "w = np.mean(geo_data[\"lon\"]) - 0.15\n",
    "    \n",
    "grid = []\n",
    "# create the grid\n",
    "for lat in latitude_partition:\n",
    "    for lon in longitude_partition:\n",
    "        grid.append((lat,lon))\n",
    "        \n",
    "#we obtain the latitude and longitude for the dict from the grid points  \n",
    "lat = [item[0] for item in grid]\n",
    "lon = [item[1] for item in grid]\n",
    "    \n",
    "#build the dict\n",
    "geographical_grid_data = {\"lat\": lat,\n",
    "                          \"lon\": lon}\n",
    "\n",
    "#create the plot\n",
    "geo_data = geographical_grid_data\n",
    "\n",
    "# plot it\n",
    "geoplotlib.dot(geographical_grid_data)\n",
    "bbox = BoundingBox(north = n, south = s, west = w, east = e)\n",
    "geoplotlib.set_bbox(bbox)\n",
    "geoplotlib.inline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create list of labels\n",
    "y = list()\n",
    "for case_type in plotting_data['Descriptor']:\n",
    "    if case_type == \"Noise: Construction Before/After Hours (NM1)\":\n",
    "        y.append(1)\n",
    "    elif case_type == \"Noise, Barking Dog (NR5)\":\n",
    "        y.append(2)\n",
    "    elif case_type == \"Noise: Alarms (NR3)\":\n",
    "        y.append(3)\n",
    "\n",
    "# get latitudes for the 3 types\n",
    "latitudes = [float(item) for item in plotting_data['Latitude'] if not math.isnan(item)]\n",
    "# get longitudes for the 3 crimes\n",
    "longitudes = [float(item) for item in plotting_data['Longitude'] if not math.isnan(item)]\n",
    "# build X as a list of lists \n",
    "X = [[latitudes[item], longitudes[item]] for item in range(len(latitudes))]\n",
    "print 'Len X: ', len(X)\n",
    "\n",
    "X_test = [list(item) for item in grid] \n",
    "print 'Len X_Test: ', len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def KNN(X, y, X_test, num_neighbors):\n",
    "\n",
    "    knn=neighbors.KNeighborsClassifier(n_neighbors=num_neighbors)\n",
    "    #train the classifier\n",
    "    knn.fit(X, y)\n",
    "    # predict the labels\n",
    "    return knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def color_grid(Z,geo_data, N):\n",
    "    num_grid_points = N*N\n",
    "\n",
    "    colorConst = {}\n",
    "    colorConst['lat'] = []\n",
    "    colorConst['lon'] = []\n",
    "    colorDog = {}\n",
    "    colorDog['lat'] = []\n",
    "    colorDog['lon'] = []\n",
    "    colorAlarm = {}\n",
    "    colorAlarm['lat'] = []\n",
    "    colorAlarm['lon'] = []\n",
    "\n",
    "    for i in range(num_grid_points):\n",
    "        if (Z[i] == 1):\n",
    "            colorConst['lat'].append(geo_data['lat'][i])\n",
    "            colorConst['lon'].append(geo_data['lon'][i])\n",
    "        if (Z[i] == 2):\n",
    "            colorDog['lat'].append(geo_data['lat'][i])\n",
    "            colorDog['lon'].append(geo_data['lon'][i])\n",
    "        if (Z[i] == 3):\n",
    "            colorAlarm['lat'].append(geo_data['lat'][i])\n",
    "            colorAlarm['lon'].append(geo_data['lon'][i])\n",
    "\n",
    "    # bbox dimensions\n",
    "    n = np.mean(geo_data[\"lat\"]) + 0.135\n",
    "    s = np.mean(geo_data[\"lat\"]) - 0.15\n",
    "    e = np.mean(geo_data[\"lon\"]) + 0.135\n",
    "    w = np.mean(geo_data[\"lon\"]) - 0.15\n",
    "    \n",
    "    geoplotlib.dot(colorConst, color='green')\n",
    "    geoplotlib.dot(colorDog, color='red')\n",
    "    geoplotlib.dot(colorAlarm, color='blue')\n",
    "    bbox = BoundingBox(north = n, south = s, west = w, east = e)\n",
    "    geoplotlib.set_bbox(bbox)\n",
    "    geoplotlib.inline()\n",
    "\n",
    "print \"K=5 NEAREST NEIGHBORS:\"\n",
    "print \"Green: Construction Before/After Hours\"\n",
    "print \"Red: Barking Dog\"\n",
    "print \"Blue: Alarm\"\n",
    "Z = KNN(X, y, X_test, 5)\n",
    "color_grid(Z,geo_data,N)\n",
    "\n",
    "print \"K=10 NEAREST NEIGHBORS:\"\n",
    "print \"Green: Construction Before/After Hours\"\n",
    "print \"Red: Barking Dog\"\n",
    "print \"Blue: Alarm\"\n",
    "Z = KNN(X, y, X_test, 10)\n",
    "color_grid(Z, geo_data, N)\n",
    "\n",
    "print \"K=30 NEAREST NEIGHBORS:\"\n",
    "print \"Green: Construction Before/After Hours\"\n",
    "print \"Red: Barking Dog\"\n",
    "print \"Blue: Alarm\"\n",
    "Z = KNN(X, y, X_test, 30)\n",
    "color_grid(Z, geo_data, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove NaN ZIP codes form the data\n",
    "data2016 = data2016[np.isfinite(data2016['Incident Zip'])]\n",
    "\n",
    "#add columns for date and time\n",
    "data2016['date'] = pd.DatetimeIndex(data2016['Created Date']).date\n",
    "data2016['time'] = pd.DatetimeIndex(data2016['Created Date']).time\n",
    "\n",
    "#transform date to ordinal for the classifier\n",
    "data2016['date_ord']=data2016['date'].apply(lambda x: x.toordinal())\n",
    "\n",
    "#translate time into minutes\n",
    "data2016['time_n_min']=data2016['time'].apply(lambda x: x.hour*60 + x.minute + x.second/60)\n",
    "\n",
    "#create a funtion to categorize \"name\" variables like Street name or Descriptor\n",
    "def categorize_target(df, target_column, new_col):\n",
    "\n",
    "    df_mod = df.copy()\n",
    "    targets = df_mod[target_column].unique()\n",
    "    map_to_int = {name: n for n, name in enumerate(targets)}\n",
    "    df_mod[new_col] = df_mod[target_column].replace(map_to_int)\n",
    "\n",
    "    return (df_mod)\n",
    "\n",
    "#Categorize Descriptor\n",
    "new_col= \"Target\"\n",
    "data2016_descrp_cat = categorize_target(data2016, \"Descriptor\",new_col)\n",
    "\n",
    "#Categorize Street Name\n",
    "new_col= \"street_cat\"\n",
    "data2016_cat = categorize_target(data2016_descrp_cat, \"Street Name\",new_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2016_cat.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define function to preapre data for classifiers\n",
    "\n",
    "def prep_data (data2016_cat, features, target,sample_size):\n",
    "    \n",
    "    train_df = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    split_point = int(round(len(data2016_cat)*sample_size))\n",
    "\n",
    "    if len(data2016_cat) > split_point : # len(df) > 10 would also work\n",
    "        train_df = data2016_cat[:split_point]\n",
    "        test_df = data2016_cat[split_point:]\n",
    "\n",
    "    y = train_df[target]\n",
    "    X = train_df[features]\n",
    "    X_test = test_df[features]\n",
    "    Y_test = test_df[target]\n",
    "    \n",
    "    return(X,y,X_test,Y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample size 90% - 10% / Time, Date, Street Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','time_n_min','street_cat']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time, Date, ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','time_n_min','Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "\n",
    "tr.fit(X, y)\n",
    "\n",
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date and ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "\n",
    "tr.fit(X, y)\n",
    "\n",
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "####  ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "\n",
    "tr.fit(X, y)\n",
    "\n",
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['street_cat']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "\n",
    "tr.fit(X, y)\n",
    "\n",
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 80-20% data - Date, time and ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','time_n_min','Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.8\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "tr = tree.DecisionTreeClassifier()\n",
    "\n",
    "tr.fit(X, y)\n",
    "\n",
    "tr_predicted = tr.predict(X_test)\n",
    "\n",
    "tr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','time_n_min','Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "RFC.fit(X,y)\n",
    "\n",
    "RFC_predicted = RFC.predict(X_test)\n",
    "\n",
    "RFC.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['street_cat']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "\n",
    "RFC = RandomForestClassifier(n_estimators = 50)\n",
    "\n",
    "RFC.fit(X,y)\n",
    "\n",
    "RFC_predicted = RFC.predict(X_test)\n",
    "\n",
    "RFC.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### K Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['date_ord','time_n_min','Incident Zip']\n",
    "target = ['Target']\n",
    "sample_size = 0.9\n",
    "\n",
    "X,y,X_test,Y_test = prep_data(data2016_cat,features,target,sample_size)\n",
    "\n",
    "KNC = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "KNC.fit(X,y)\n",
    "\n",
    "KNC_predicted = KNC.predict(X_test)\n",
    "\n",
    "KNC.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
